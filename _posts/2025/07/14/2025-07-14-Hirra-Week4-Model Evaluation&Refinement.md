---
title: Week 4 â€“ Model Evaluation & Refinement
date: 2025-07-14
time: "09:00"
author: hirraa
categories: ["NLP", "Machine Learning", "Deep Learning" , "Hyperparameter Tuning"]
layout: post
---

This week I tested my machine learning models by merging all 3 socialâ€‘media datasets to create a more diverse trainâ€“validation split and assess how well they handle domain shifts. 

I then ran my deep learning pipeline, using transformer models like BERTâ€¯BASE and RoBERTa, through both training and testing phases, logging key metrics (F1, ROCâ€‘AUC, precision, recall, accuracy) ğŸ“Š. I also compared these results against our baseline machine learning models to see which produced the best result.

Challenge: the larger transformer models are taking significantly longer to train and evaluate â³

â¡ï¸ Next steps: Iâ€™ll experiment with smarter batch size schedules (and possibly mixedâ€‘precision training) to speed up training and then fineâ€‘tune hyperparameters based on the newly collected results.
